# ERCP Protocol Server Configuration
# Copy this file to .env and customize for your environment

# ============================
# SECURITY CONFIGURATION
# ============================

# Secret key for HMAC signing (REQUIRED - minimum 32 bytes)
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
ERCP_SECRET_KEY=your-secret-key-here-must-be-at-least-32-bytes-long

# API Keys for authentication (comma-separated)
# If not set, authentication is disabled (NOT RECOMMENDED for production)
# Generate keys with: python -c "import secrets; print(secrets.token_urlsafe(32))"
ERCP_API_KEYS=key1,key2,key3

# ============================
# RATE LIMITING
# ============================

# Maximum requests per time window per client
RATE_LIMIT_REQUESTS=100

# Time window in seconds
RATE_LIMIT_WINDOW=60

# ============================
# REQUEST LIMITS
# ============================

# Maximum request payload size in bytes (default: 1MB)
MAX_REQUEST_SIZE=1048576

# ============================
# CORS CONFIGURATION
# ============================

# Allowed origins for CORS (comma-separated)
# Use "*" for development only, specify exact origins in production
CORS_ORIGINS=https://your-frontend.com,https://your-app.com

# ============================
# TRUSTED HOSTS (Production Only)
# ============================

# Environment setting (development/production)
ENVIRONMENT=development

# Allowed hostnames (comma-separated) - only enforced in production
ALLOWED_HOSTS=localhost,127.0.0.1,your-domain.com

# ============================
# LOGGING
# ============================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ============================
# DATABASE (Optional - for production)
# ============================

# If using PostgreSQL for trace storage
# DATABASE_URL=postgresql://user:password@localhost:5432/ercp_db

# If using Redis for rate limiting
# REDIS_URL=redis://localhost:6379/0

# ============================
# MODEL CONFIGURATION (Optional)
# ============================

# Default model to use
DEFAULT_MODEL=local-llm

# Model API endpoints (if using external services)
# OPENAI_API_KEY=your-openai-key
# ANTHROPIC_API_KEY=your-anthropic-key

# ============================
# MONITORING (Optional)
# ============================

# Sentry DSN for error tracking
# SENTRY_DSN=https://your-sentry-dsn

# Prometheus metrics endpoint enabled
# ENABLE_METRICS=true
